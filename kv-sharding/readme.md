## Распределенное key-value хранилище с шардингом

В этой задаче вам надо реализовать распределенную систему, в которой можно хранить записи вида `(ключ, значение)`. Ключами и значениями могут быть произвольные строки, их распределение неизвестно. В системе может храниться только одна запись с данным ключом. Для каких-то ключей записи могут отсутствовать.

Cистема должна поддерживать следующие операции для работы с данными:
- `GET(key)` - вернуть значение записи с ключом `key` (может выдать пустое значение, если записи с этим ключом нет),
- `PUT(key, value)` - сохранить запись с ключом `key` и значением `value`,
- `DELETE(key)` - удалить запись с ключом `key`.

Система состоит из нескольких идентичных узлов, с каждым из которых связан процесс _Node_. Каждый узел отвечает за хранение части данных Хранить данные на диске не требуется, достаточно держать все в памяти.

Для обеспечения горизонтальной масштабируемости хранилища применяется шардинг. Для любого возможного значения ключа должен быть определен узел, "отвечающий" за хранение соответствующей записи. Таким образом, каждый узел в системе отвечает за некоторое подмножество ключей (один или несколько шардов) и хранение связанных с этими ключами записей. При этом требуется, чтобы каждый узел хранил примерно одинаковую долю данных - в идеале R/N записей, где R - число записей, а N - число узлов. В тестах допустимым считается отклонение не более на 20% от идеального значения.

Каждый узел может обслуживать локальные запросы `GET`, `PUT` и `DELETE` к любым ключам. Если узел не отвечает за данный ключ, то он должен переслать запрос правильному узлу, дождаться ответ и вернуть его локальному клиенту. По умолчанию, вы можете поддерживать на каждом узле всю информацию, необходимую для определения узла отвечающего за ключ. В качестве бонусного задания, вы можете реализовать DHT, где каждый узел знает информацию только о части узлов и пересылает запрос по цепочке (бонус +4 балла).

В ходе работы системы в неё могут добавляться новые узлы, а старые могут отключаться. Обычно это происходит в штатном режиме по команде администратора. Для этого предусмотрены служебные операции `JOIN(seed)` и `LEAVE()`, аналогичные предыдущему заданию про group membership. Однако помимо входа или выхода из группы, также должны быть выполнены следующие требования.

При изменении состава узлов должна происходить _перебалансировка_ - перераспределение ключей (зон ответственности) и записей (хранимых данных) между узлами для восстановления ранее описанных свойств. Во-первых, для любого возможного значения ключа должен существовать узел, отвечающий за него. Во-вторых, каждый узел по-прежнему должен хранить примерно одинаковую долю данных. Таким образом, при добавлении нового узла, он должен принять на себя некоторую часть ключей и хранимых записей. А при отключении узла, ключи, за которые он отвечал, и хранимые им записи должны распределяться между оставшимися узлами. Перебалансировка сопряжена с расходами на перемещение хранимых данных между узлами. Требуется минимизировать эти расходы - в идеале должно перемещаться только R/N записей. В тестах допустимым считается отклонение не более на 20% от идеального значения.

Как обычно, узлы и сеть могут отказывать. Ваша реализация должна уметь обнаруживать отказы и автоматически обрабатывать их. Для этого можно использовать решение прошлого задания про group membership. В случае отказа узла, ключи, за которые он отвечал, должны распределяться между оставшимися узлами как и в случае штатного отключения. Однако хранимые на отказавшем узле записи становятся недоступны или теряются. Мы решим эту проблему в рамках следующего задания.

Для целей тестирования ваша реализация должна поддерживать дополнительные служебные операции с любого узла:
- `GET_MEMBERS()` - возвращает список идентификаторов узлов системы (аналогично предыдущему заданию),
- `LOOKUP(key)` - возвращает имя узла, отвечающего за хранение ключа `key`,
- `COUNT_RECORDS()` - возвращает число записей, хранимых на узле,
- `DUMP_KEYS()` - возвращает ключи записей, хранимых на узле.

Форматы запросов и ответов на все требуемые операции описаны в [заготовке решения](solution/node.py).

## Тестирование

Необходимые зависимости должны быть уже установлены (см. предыдущие задания). Добавьте корень репозитория в переменную окружения PYTHONPATH и запустите тесты:

```console
$ PYTHONPATH=$ROOT_DIRECTORY_PATH python3 test.py solution
```

Если Вам нужно больше отладочной информации, добавьте флаг `-v` (показывает сообщения) или `-d` (показывает вывод вашей реализации) к тестированию. Для анализа больших логов рекомендуется перенаправлять вывод тестов в файл, добавив к команде ` &>log`, и затем искать нужную информацию, например с помощью grep.

Поднимаются несколько процессов узлов, которые коммуницируют между собой через `test_server`. Все аналогично предыдущим задачам.

Мы уже написали за Вас тесты, которы должны проходить при правильном решении. Вы можете добавлять новые тесты, по умолчанию они не будут оцениваться. Однако если вы придумаете и реализуете тест, который увеличит покрытие наших тестов, то за него можно получить бонус 2 балла. За деталями о том, как мы тестируем, обращайтесь к тестам, осознать, что там происходит -- Ваша задача.

## Оценивание

Распределение баллов по требованиям и тестам:
- Базовый функционал (работают GET, PUT, DELETE в статичной конфигурации) - 2
    - BasicTestCase - 1
    - DeleteTestCase - 1
- Переконфигурация системы (работают JOIN и LEAVE, данные не теряются) - 3
    - LeaveTestCase - 1
    - SwingTestCase - 2
- Обработка отказов узлов - 2
    - CrashTestCase - 2
- Равномерное распределение данных и минимизация перемещения данных при перебалансировке - 3
    - BalancedStaticCase - 1
    - BalancedJoinCase - 1
    - BalancedLeaveCase - 1

## Сдача

Сдача и проверка решений будет вестись через сервис Gradescope.
См. инструкцию в первой задаче.

Далее зайдите в Assignments, там вы увидите задачу KV Sharding, в которую можно сдавать только zip архивы. Поместите тесты и решение в архив следующей командой:

```console
$ zip -r solution.zip test.py solution/
```

Добавьте  в папку `solution` файл `readme.md` с кратким описанием вашего решения и дополнительными комментариями, который также попадет в архив. Также, если вы добавляете свои тесты, то напишите к ним docstring - что проверяется в тесте и каким образом. **В случае отсутствия описаний решения и тестов оценка может быть снижена на 1 балл**.

Далее сдайте Ваш `solution.zip`. Дождитесь пока отработают Ваши тесты на Вашем решении (учтите, что это может занять несколько минут из-за нагрузки серверов). Если все тесты прошли успешно, то решение проставляется 2 балла и решение принимается на ручную проверку. Если какие-то тесты не прошли, то выставляется 0 баллов, и решение не принимается на ручную проверку.

Если Вы не смогли что-то реализовать, можете закомментировать некоторые тесты в [test.py](./test.py), но обязательно отразите почему Вы это сделали в readme-файле. Это сильно упростит нам проверку.

Дедлайн задачи -- __2 недели__, в Gradescope корректно проставлена дата окончания.